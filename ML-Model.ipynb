{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model (nn.Module):\n",
    "    def __init__(self, iLayers=146, h1=72, h2=36, h3=16, h4=8, oLayer=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(iLayers, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, h3)\n",
    "        self.fc4 = nn.Linear(h3, h4)\n",
    "        self.out = nn.Linear(h4, oLayer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(16)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_24 = pd.read_csv('Data Set/21-24Stats.csv')\n",
    "matchups_24 = pd.read_csv('Data Set/24Matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = matchups_24['SCORE_DIF'].values.reshape(-1,1)\n",
    "x = matchups_24.merge(stats_24, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_24, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1', 'SCORE_DIF'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "    \n",
    "# Remove NaNs and Infs from the data\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))\n",
    "y = torch.nan_to_num(torch.tensor(y, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# if error doesn't go down after a bunch of iterations (epochs), lower our learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and loss: 1.985657811164856\n",
      "Epoch: 10 and loss: 1.9852544069290161\n",
      "Epoch: 20 and loss: 1.9848746061325073\n",
      "Epoch: 30 and loss: 1.9844902753829956\n",
      "Epoch: 40 and loss: 1.9840620756149292\n",
      "Epoch: 50 and loss: 1.983490228652954\n",
      "Epoch: 60 and loss: 1.9827656745910645\n",
      "Epoch: 70 and loss: 1.9818917512893677\n",
      "Epoch: 80 and loss: 1.9807755947113037\n",
      "Epoch: 90 and loss: 1.979353666305542\n",
      "Epoch: 100 and loss: 1.9776556491851807\n",
      "Epoch: 110 and loss: 1.9756227731704712\n",
      "Epoch: 120 and loss: 1.9731968641281128\n",
      "Epoch: 130 and loss: 1.9702810049057007\n",
      "Epoch: 140 and loss: 1.9667255878448486\n",
      "Epoch: 150 and loss: 1.9623934030532837\n",
      "Epoch: 160 and loss: 1.9570508003234863\n",
      "Epoch: 170 and loss: 1.950446367263794\n",
      "Epoch: 180 and loss: 1.9423702955245972\n",
      "Epoch: 190 and loss: 1.9326366186141968\n",
      "Epoch: 200 and loss: 1.920955777168274\n",
      "Epoch: 210 and loss: 1.9070416688919067\n",
      "Epoch: 220 and loss: 1.890618920326233\n",
      "Epoch: 230 and loss: 1.8714314699172974\n",
      "Epoch: 240 and loss: 1.8491531610488892\n",
      "Epoch: 250 and loss: 1.8236830234527588\n",
      "Epoch: 260 and loss: 1.794947624206543\n",
      "Epoch: 270 and loss: 1.7629704475402832\n",
      "Epoch: 280 and loss: 1.7278668880462646\n",
      "Epoch: 290 and loss: 1.689810872077942\n",
      "Epoch: 300 and loss: 1.6492894887924194\n",
      "Epoch: 310 and loss: 1.6069120168685913\n",
      "Epoch: 320 and loss: 1.5634649991989136\n",
      "Epoch: 330 and loss: 1.5197899341583252\n",
      "Epoch: 340 and loss: 1.4768153429031372\n",
      "Epoch: 350 and loss: 1.4355497360229492\n",
      "Epoch: 360 and loss: 1.396745204925537\n",
      "Epoch: 370 and loss: 1.3609148263931274\n",
      "Epoch: 380 and loss: 1.3284987211227417\n",
      "Epoch: 390 and loss: 1.2995295524597168\n",
      "Epoch: 400 and loss: 1.2736598253250122\n",
      "Epoch: 410 and loss: 1.250396490097046\n",
      "Epoch: 420 and loss: 1.2291064262390137\n",
      "Epoch: 430 and loss: 1.2093737125396729\n",
      "Epoch: 440 and loss: 1.1905853748321533\n",
      "Epoch: 450 and loss: 1.1722127199172974\n",
      "Epoch: 460 and loss: 1.1537319421768188\n",
      "Epoch: 470 and loss: 1.135512113571167\n",
      "Epoch: 480 and loss: 1.1173701286315918\n",
      "Epoch: 490 and loss: 1.099116325378418\n",
      "Epoch: 500 and loss: 1.080781102180481\n",
      "Epoch: 510 and loss: 1.0625920295715332\n",
      "Epoch: 520 and loss: 1.0442332029342651\n",
      "Epoch: 530 and loss: 1.0254900455474854\n",
      "Epoch: 540 and loss: 1.0063848495483398\n",
      "Epoch: 550 and loss: 0.9868453741073608\n",
      "Epoch: 560 and loss: 0.9668859243392944\n",
      "Epoch: 570 and loss: 0.9464480876922607\n",
      "Epoch: 580 and loss: 0.9258908033370972\n",
      "Epoch: 590 and loss: 0.9052437543869019\n",
      "Test Loss: 2.5049\n"
     ]
    }
   ],
   "source": [
    "epochs = 600\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "  # Go forward and get a prediction\n",
    "  y_pred = model(x_train) # Get predicted results\n",
    "\n",
    "  loss = criterion(y_pred, y_train)\n",
    "  loss = loss / len(x_train) \n",
    "\n",
    "  # print every 10 epoch\n",
    "  if i % 10 == 0:\n",
    "    print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "  # Do some back propagation: take the error rate of forward propagation and feed it back\n",
    "  # thru the network to fine tune the weights\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x_test)\n",
    "    test_loss = criterion(test_pred, y_test) / len(x_test)\n",
    "    print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_25 = pd.read_csv('Data Set/22-25Stats.csv')\n",
    "matchups_25 = pd.read_csv('Data Set/25Matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = matchups_25['SCORE_DIF'].values.reshape(-1,1)\n",
    "x = matchups_25.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1', 'SCORE_DIF'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "    \n",
    "# Remove NaNs and Infs from the data\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))\n",
    "y = torch.nan_to_num(torch.tensor(y, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and loss: 1.4653065204620361\n",
      "Epoch: 10 and loss: 1.3763387203216553\n",
      "Epoch: 20 and loss: 1.2868996858596802\n",
      "Epoch: 30 and loss: 1.2317677736282349\n",
      "Epoch: 40 and loss: 1.193682312965393\n",
      "Epoch: 50 and loss: 1.162406086921692\n",
      "Epoch: 60 and loss: 1.1351068019866943\n",
      "Epoch: 70 and loss: 1.1102097034454346\n",
      "Epoch: 80 and loss: 1.0867199897766113\n",
      "Epoch: 90 and loss: 1.0639920234680176\n",
      "Epoch: 100 and loss: 1.0416439771652222\n",
      "Epoch: 110 and loss: 1.0195294618606567\n",
      "Epoch: 120 and loss: 0.9973545074462891\n",
      "Epoch: 130 and loss: 0.9748269319534302\n",
      "Epoch: 140 and loss: 0.9520037174224854\n",
      "Epoch: 150 and loss: 0.9291054606437683\n",
      "Epoch: 160 and loss: 0.9052437543869019\n",
      "Epoch: 170 and loss: 0.8805640339851379\n",
      "Epoch: 180 and loss: 0.8558115363121033\n",
      "Epoch: 190 and loss: 0.8318691849708557\n",
      "Test Loss: 2.9849\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "  # Go forward and get a prediction\n",
    "  y_pred = model(x_train) # Get predicted results\n",
    "\n",
    "  loss = criterion(y_pred, y_train)\n",
    "  loss = loss / len(x_train) \n",
    "\n",
    "  # print every 10 epoch\n",
    "  if i % 10 == 0:\n",
    "    print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "  # Do some back propagation: take the error rate of forward propagation and feed it back\n",
    "  # thru the network to fine tune the weights\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x_test)\n",
    "    test_loss = criterion(test_pred, y_test) / len(x_test)\n",
    "    print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/R64.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 1 | + 16.0 Points\n",
      "Match 2: Team 2 | + 8.0 Points\n",
      "Match 3: Team 2 | + 2.0 Points\n",
      "Match 4: Team 2 | + 3.0 Points\n",
      "Match 5: Team 2 | + 5.0 Points\n",
      "Match 6: Team 1 | + 3.0 Points\n",
      "Match 7: Team 2 | + 2.0 Points\n",
      "Match 8: Team 1 | + 2.0 Points\n",
      "Match 9: Team 1 | + 9.0 Points\n",
      "Match 10: Team 2 | + 9.0 Points\n",
      "Match 11: Team 2 | + 5.0 Points\n",
      "Match 12: Team 2 | + 3.0 Points\n",
      "Match 13: Team 2 | + 4.0 Points\n",
      "Match 14: Team 1 | + 3.0 Points\n",
      "Match 15: Team 2 | + 4.0 Points\n",
      "Match 16: Team 1 | + 5.0 Points\n",
      "Match 17: Team 1 | + 20.0 Points\n",
      "Match 18: Team 2 | + 6.0 Points\n",
      "Match 19: Team 2 | + 4.0 Points\n",
      "Match 20: Team 1 | + 3.0 Points\n",
      "Match 21: Team 2 | + 5.0 Points\n",
      "Match 22: Team 1 | + 9.0 Points\n",
      "Match 23: Team 2 | + 4.0 Points\n",
      "Match 24: Team 1 | + 6.0 Points\n",
      "Match 25: Team 1 | + 17.0 Points\n",
      "Match 26: Team 2 | + 5.0 Points\n",
      "Match 27: Team 2 | + 3.0 Points\n",
      "Match 28: Team 2 | + 3.0 Points\n",
      "Match 29: Team 2 | + 7.0 Points\n",
      "Match 30: Team 1 | + 1.0 Points\n",
      "Match 31: Team 2 | + 4.0 Points\n",
      "Match 32: Team 1 | + 16.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/R32.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 1 | + 8.0 Points\n",
      "Match 2: Team 2 | + 3.0 Points\n",
      "Match 3: Team 2 | + 3.0 Points\n",
      "Match 4: Team 1 | + 1.0 Points\n",
      "Match 5: Team 1 | + 8.0 Points\n",
      "Match 6: Team 1 | + 1.0 Points\n",
      "Match 7: Team 2 | + 3.0 Points\n",
      "Match 8: Team 2 | + 3.0 Points\n",
      "Match 9: Team 1 | + 12.0 Points\n",
      "Match 10: Team 2 | + 5.0 Points\n",
      "Match 11: Team 2 | + 3.0 Points\n",
      "Match 12: Team 2 | + 5.0 Points\n",
      "Match 13: Team 1 | + 7.0 Points\n",
      "Match 14: Team 1 | + 3.0 Points\n",
      "Match 15: Team 2 | + 5.0 Points\n",
      "Match 16: Team 2 | + 5.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/S16.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 1 | + 11.0 Points\n",
      "Match 2: Team 2 | + 1.0 Points\n",
      "Match 3: Team 1 | + 1.0 Points\n",
      "Match 4: Team 2 | + 4.0 Points\n",
      "Match 5: Team 1 | + 2.0 Points\n",
      "Match 6: Team 2 | + 4.0 Points\n",
      "Match 7: Team 2 | + 1.0 Points\n",
      "Match 8: Team 2 | + 6.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/E8.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 1 | + 14.0 Points\n",
      "Match 2: Team 2 | + 3.0 Points\n",
      "Match 3: Team 2 | + 3.0 Points\n",
      "Match 4: Team 2 | + 5.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/F4.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 1 | + 2.0 Points\n",
      "Match 2: Team 2 | + 5.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/Champ.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 2 | + 1.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
