{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model (nn.Module):\n",
    "    def __init__(self, iLayers=146, h1=72, h2=36, h3=16, h4=8, oLayer=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(iLayers, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, h3)\n",
    "        self.fc4 = nn.Linear(h3, h4)\n",
    "        self.out = nn.Linear(h4, oLayer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(16)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_24 = pd.read_csv('Data Set/21-24Stats.csv')\n",
    "matchups_24 = pd.read_csv('Data Set/24Matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = matchups_24['SCORE_DIF'].values.reshape(-1,1)\n",
    "x = matchups_24.merge(stats_24, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_24, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1', 'SCORE_DIF'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "    \n",
    "# Remove NaNs and Infs from the data\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))\n",
    "y = torch.nan_to_num(torch.tensor(y, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# if error doesn't go down after a bunch of iterations (epochs), lower our learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and loss: 1.9268829822540283\n",
      "Epoch: 10 and loss: 1.9264332056045532\n",
      "Epoch: 20 and loss: 1.9260013103485107\n",
      "Epoch: 30 and loss: 1.9255636930465698\n",
      "Epoch: 40 and loss: 1.925047755241394\n",
      "Epoch: 50 and loss: 1.9243937730789185\n",
      "Epoch: 60 and loss: 1.9235877990722656\n",
      "Epoch: 70 and loss: 1.9225722551345825\n",
      "Epoch: 80 and loss: 1.9212515354156494\n",
      "Epoch: 90 and loss: 1.9196399450302124\n",
      "Epoch: 100 and loss: 1.917697787284851\n",
      "Epoch: 110 and loss: 1.9153530597686768\n",
      "Epoch: 120 and loss: 1.9124780893325806\n",
      "Epoch: 130 and loss: 1.9089579582214355\n",
      "Epoch: 140 and loss: 1.9046109914779663\n",
      "Epoch: 150 and loss: 1.899287223815918\n",
      "Epoch: 160 and loss: 1.8927927017211914\n",
      "Epoch: 170 and loss: 1.88491690158844\n",
      "Epoch: 180 and loss: 1.875443696975708\n",
      "Epoch: 190 and loss: 1.8640830516815186\n",
      "Epoch: 200 and loss: 1.8505805730819702\n",
      "Epoch: 210 and loss: 1.8347023725509644\n",
      "Epoch: 220 and loss: 1.81623375415802\n",
      "Epoch: 230 and loss: 1.7948968410491943\n",
      "Epoch: 240 and loss: 1.7704503536224365\n",
      "Epoch: 250 and loss: 1.742740273475647\n",
      "Epoch: 260 and loss: 1.711705207824707\n",
      "Epoch: 270 and loss: 1.6773831844329834\n",
      "Epoch: 280 and loss: 1.6399226188659668\n",
      "Epoch: 290 and loss: 1.5996320247650146\n",
      "Epoch: 300 and loss: 1.557012915611267\n",
      "Epoch: 310 and loss: 1.5126343965530396\n",
      "Epoch: 320 and loss: 1.4672770500183105\n",
      "Epoch: 330 and loss: 1.4217009544372559\n",
      "Epoch: 340 and loss: 1.3767526149749756\n",
      "Epoch: 350 and loss: 1.3338961601257324\n",
      "Epoch: 360 and loss: 1.2941750288009644\n",
      "Epoch: 370 and loss: 1.2582964897155762\n",
      "Epoch: 380 and loss: 1.2266743183135986\n",
      "Epoch: 390 and loss: 1.199347972869873\n",
      "Epoch: 400 and loss: 1.175675392150879\n",
      "Epoch: 410 and loss: 1.1547155380249023\n",
      "Epoch: 420 and loss: 1.1358882188796997\n",
      "Epoch: 430 and loss: 1.1183443069458008\n",
      "Epoch: 440 and loss: 1.101956844329834\n",
      "Epoch: 450 and loss: 1.0862016677856445\n",
      "Epoch: 460 and loss: 1.070647120475769\n",
      "Epoch: 470 and loss: 1.055031418800354\n",
      "Epoch: 480 and loss: 1.0394999980926514\n",
      "Epoch: 490 and loss: 1.0237927436828613\n",
      "Epoch: 500 and loss: 1.0078918933868408\n",
      "Epoch: 510 and loss: 0.9918939471244812\n",
      "Epoch: 520 and loss: 0.9759641885757446\n",
      "Epoch: 530 and loss: 0.9600748419761658\n",
      "Epoch: 540 and loss: 0.9442532658576965\n",
      "Epoch: 550 and loss: 0.9283866882324219\n",
      "Epoch: 560 and loss: 0.9123712182044983\n",
      "Epoch: 570 and loss: 0.8961127996444702\n",
      "Epoch: 580 and loss: 0.8795908093452454\n",
      "Epoch: 590 and loss: 0.8628394603729248\n",
      "Test Loss: 3.0630\n"
     ]
    }
   ],
   "source": [
    "epochs = 600\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "  # Go forward and get a prediction\n",
    "  y_pred = model(x_train) # Get predicted results\n",
    "\n",
    "  loss = criterion(y_pred, y_train)\n",
    "  loss = loss / len(x_train) \n",
    "\n",
    "  # print every 10 epoch\n",
    "  if i % 10 == 0:\n",
    "    print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "  # Do some back propagation: take the error rate of forward propagation and feed it back\n",
    "  # thru the network to fine tune the weights\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x_test)\n",
    "    test_loss = criterion(test_pred, y_test) / len(x_test)\n",
    "    print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_25 = pd.read_csv('Data Set/22-25Stats.csv')\n",
    "matchups_25 = pd.read_csv('Data Set/25Matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = matchups_25['SCORE_DIF'].values.reshape(-1,1)\n",
    "x = matchups_25.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1', 'SCORE_DIF'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "    \n",
    "# Remove NaNs and Infs from the data\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))\n",
    "y = torch.nan_to_num(torch.tensor(y, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and loss: 1.5790315866470337\n",
      "Epoch: 10 and loss: 1.468571662902832\n",
      "Epoch: 20 and loss: 1.3566924333572388\n",
      "Epoch: 30 and loss: 1.2917975187301636\n",
      "Epoch: 40 and loss: 1.2552143335342407\n",
      "Epoch: 50 and loss: 1.2269881963729858\n",
      "Epoch: 60 and loss: 1.2029179334640503\n",
      "Epoch: 70 and loss: 1.1813461780548096\n",
      "Epoch: 80 and loss: 1.1612091064453125\n",
      "Epoch: 90 and loss: 1.1417486667633057\n",
      "Epoch: 100 and loss: 1.1228500604629517\n",
      "Epoch: 110 and loss: 1.1045985221862793\n",
      "Epoch: 120 and loss: 1.0865333080291748\n",
      "Epoch: 130 and loss: 1.0689526796340942\n",
      "Epoch: 140 and loss: 1.051456093788147\n",
      "Epoch: 150 and loss: 1.0342626571655273\n",
      "Epoch: 160 and loss: 1.0170843601226807\n",
      "Epoch: 170 and loss: 0.9997708797454834\n",
      "Epoch: 180 and loss: 0.982223391532898\n",
      "Epoch: 190 and loss: 0.9644133448600769\n",
      "Test Loss: 3.2941\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "  # Go forward and get a prediction\n",
    "  y_pred = model(x_train) # Get predicted results\n",
    "\n",
    "  loss = criterion(y_pred, y_train)\n",
    "  loss = loss / len(x_train) \n",
    "\n",
    "  # print every 10 epoch\n",
    "  if i % 10 == 0:\n",
    "    print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "  # Do some back propagation: take the error rate of forward propagation and feed it back\n",
    "  # thru the network to fine tune the weights\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x_test)\n",
    "    test_loss = criterion(test_pred, y_test) / len(x_test)\n",
    "    print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/R64.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 1 | + 17.0 Points\n",
      "Match 2: Team 2 | + 5.0 Points\n",
      "Match 3: Team 2 | + 2.0 Points\n",
      "Match 4: Team 2 | + 1.0 Points\n",
      "Match 5: Team 2 | + 3.0 Points\n",
      "Match 6: Team 1 | + 4.0 Points\n",
      "Match 7: Team 2 | + 1.0 Points\n",
      "Match 8: Team 1 | + 4.0 Points\n",
      "Match 9: Team 1 | + 7.0 Points\n",
      "Match 10: Team 2 | + 6.0 Points\n",
      "Match 11: Team 2 | + 3.0 Points\n",
      "Match 12: Team 2 | + 4.0 Points\n",
      "Match 13: Team 2 | + 2.0 Points\n",
      "Match 14: Team 1 | + 2.0 Points\n",
      "Match 15: Team 2 | + 4.0 Points\n",
      "Match 16: Team 1 | + 5.0 Points\n",
      "Match 17: Team 1 | + 12.0 Points\n",
      "Match 18: Team 2 | + 4.0 Points\n",
      "Match 19: Team 2 | + 2.0 Points\n",
      "Match 20: Team 2 | + 5.0 Points\n",
      "Match 21: Team 2 | + 5.0 Points\n",
      "Match 22: Team 1 | + 3.0 Points\n",
      "Match 23: Team 2 | + 4.0 Points\n",
      "Match 24: Team 1 | + 2.0 Points\n",
      "Match 25: Team 1 | + 18.0 Points\n",
      "Match 26: Team 2 | + 4.0 Points\n",
      "Match 27: Team 2 | + 2.0 Points\n",
      "Match 28: Team 2 | + 6.0 Points\n",
      "Match 29: Team 2 | + 5.0 Points\n",
      "Match 30: Team 1 | + 1.0 Points\n",
      "Match 31: Team 2 | + 2.0 Points\n",
      "Match 32: Team 1 | + 6.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/R32.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 1 | + 5.0 Points\n",
      "Match 2: Team 2 | + 2.0 Points\n",
      "Match 3: Team 2 | + 2.0 Points\n",
      "Match 4: Team 1 | + 4.0 Points\n",
      "Match 5: Team 1 | + 6.0 Points\n",
      "Match 6: Team 2 | + 2.0 Points\n",
      "Match 7: Team 2 | + 3.0 Points\n",
      "Match 8: Team 2 | + 2.0 Points\n",
      "Match 9: Team 2 | + 5.0 Points\n",
      "Match 10: Team 2 | + 3.0 Points\n",
      "Match 11: Team 2 | + 3.0 Points\n",
      "Match 12: Team 2 | + 4.0 Points\n",
      "Match 13: Team 1 | + 13.0 Points\n",
      "Match 14: Team 1 | + 1.0 Points\n",
      "Match 15: Team 2 | + 3.0 Points\n",
      "Match 16: Team 2 | + 4.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/S16.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 1 | + 8.0 Points\n",
      "Match 2: Team 1 | + 4.0 Points\n",
      "Match 3: Team 1 | + 3.0 Points\n",
      "Match 4: Team 2 | + 3.0 Points\n",
      "Match 5: Team 2 | + 2.0 Points\n",
      "Match 6: Team 2 | + 4.0 Points\n",
      "Match 7: Team 1 | + 6.0 Points\n",
      "Match 8: Team 2 | + 5.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/E8.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 1 | + 5.0 Points\n",
      "Match 2: Team 1 | + 3.0 Points\n",
      "Match 3: Team 2 | + 2.0 Points\n",
      "Match 4: Team 2 | + 5.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/F4.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 1 | + 1.0 Points\n",
      "Match 2: Team 2 | + 3.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('Data Set/Champ.csv')\n",
    "x = x.merge(stats_25, left_on='TEAM_0_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.merge(stats_25, left_on='TEAM_1_ID', right_on='TEAM_ID', suffixes=('_0', '_1'))\n",
    "x = x.drop(['MATCH_ID', 'TEAM_0', 'TEAM_1', 'TEAM_0_ID', 'TEAM_1_ID', 'TEAM_ID_0', 'TEAM_ID_1'], axis=1)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "x = torch.nan_to_num(torch.tensor(x, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1: Team 2 | + 1.0 Points\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(x)\n",
    "    pred_winners = ['Team 1' if score > 0 else 'Team 2' for score in test_pred]\n",
    "    for i, winner in enumerate(pred_winners):\n",
    "        print(f\"Match {i+1}: {winner} | +{np.ceil(abs(test_pred[i].item())): } Points\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
